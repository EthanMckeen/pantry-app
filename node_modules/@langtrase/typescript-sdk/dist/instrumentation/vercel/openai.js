"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.embedPatchOpenAI = exports.generateTextPatchOpenAI = exports.streamTextPatchOpenAI = void 0;
const common_1 = require("../../constants/common");
const llm_1 = require("../../utils/llm");
const trace_attributes_1 = require("@langtrase/trace-attributes");
const api_1 = require("@opentelemetry/api");
async function streamTextPatchOpenAI(patchThis, args, originalMethod, method, tracer, langtraceVersion, sdkName, version) {
    let url;
    let path;
    // wrap the url method to get the url and path
    patchThis._wrap(args[0]?.model?.config, 'url', (originalMethod) => {
        return function (...args) {
            const result = originalMethod.apply(this, args);
            const uri = new URL(result);
            path = uri.pathname;
            url = uri.origin;
            return result;
        };
    });
    const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
    const attributes = {
        'langtrace.sdk.name': sdkName,
        'langtrace.service.name': trace_attributes_1.Vendors.VERCEL,
        'langtrace.service.type': 'framework',
        'langtrace.service.version': version,
        'langtrace.version': langtraceVersion,
        'gen_ai.request.model': args[0]?.model?.modelId,
        'url.full': '',
        'url.path': '',
        'http.max.retries': args[0]?.maxRetries,
        'gen_ai.request.stream': true,
        'gen_ai.request.temperature': args[0]?.temperature,
        'gen_ai.request.top_p': args[0]?.topP,
        'gen_ai.user': args[0]?.model?.settings?.user,
        'gen_ai.request.top_logprobs': args[0]?.model?.settings?.logprobs,
        'gen_ai.request.logprobs': args[0]?.model?.settings?.logprobs !== undefined,
        'gen_ai.request.logit_bias': JSON.stringify(args[0]?.model?.settings?.logitBias),
        'gen_ai.request.max_tokens': args[0]?.maxTokens,
        'gen_ai.request.tools': JSON.stringify(args[0]?.tools),
        ...customAttributes
    };
    const span = tracer.startSpan(method, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
    return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
        try {
            const resp = await originalMethod.apply(this, args);
            span.addEvent(trace_attributes_1.Event.GEN_AI_PROMPT, { 'gen_ai.prompt': JSON.stringify(args[0]?.messages) });
            const responseAttributes = {
                'url.full': url,
                'url.path': path
            };
            const proxiedResp = new Proxy(resp, {
                get(target, prop) {
                    if (prop === 'fullStream' || prop === 'textStream') {
                        const promptContent = args[0].messages.map((message) => message?.content).join(' ');
                        const promptTokens = (0, llm_1.calculatePromptTokens)(promptContent, attributes['gen_ai.request.model']);
                        return handleOpenAIStreamResponse(span, target[prop], { ...attributes, ...responseAttributes }, promptTokens);
                    }
                    return target[prop];
                }
            });
            return proxiedResp;
        }
        catch (error) {
            span.recordException(error);
            span.setStatus({ code: api_1.SpanStatusCode.ERROR });
            span.end();
            throw error;
        }
    });
}
exports.streamTextPatchOpenAI = streamTextPatchOpenAI;
async function generateTextPatchOpenAI(patchThis, args, originalMethod, method, tracer, langtraceVersion, sdkName, version) {
    let url;
    let path;
    // wrap the url method to get the url and path
    patchThis._wrap(args[0]?.model?.config, 'url', (originalMethod) => {
        return function (...args) {
            const result = originalMethod.apply(this, args);
            const uri = new URL(result);
            path = uri.pathname;
            url = uri.origin;
            return result;
        };
    });
    const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
    const attributes = {
        'langtrace.sdk.name': sdkName,
        'langtrace.service.name': trace_attributes_1.Vendors.VERCEL,
        'langtrace.service.type': 'framework',
        'langtrace.service.version': version,
        'langtrace.version': langtraceVersion,
        'gen_ai.request.model': args[0]?.model?.modelId,
        'url.full': '',
        'url.path': '',
        'gen_ai.request.stream': false,
        'http.max.retries': args[0]?.maxRetries,
        'gen_ai.request.temperature': args[0]?.temperature,
        'gen_ai.request.top_p': args[0]?.topP,
        'gen_ai.user': args[0]?.model?.settings?.user,
        'gen_ai.request.top_logprobs': args[0]?.model?.settings?.logprobs,
        'gen_ai.request.logprobs': args[0]?.model?.settings?.logprobs !== undefined,
        'gen_ai.request.logit_bias': JSON.stringify(args[0]?.model?.settings?.logitBias),
        'gen_ai.request.max_tokens': args[0]?.maxTokens,
        'gen_ai.request.tools': JSON.stringify(args[0]?.tools),
        ...customAttributes
    };
    const span = tracer.startSpan(method, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
    return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
        try {
            const resp = await originalMethod.apply(this, args);
            const responses = JSON.stringify(resp?.responseMessages);
            span.addEvent(trace_attributes_1.Event.GEN_AI_PROMPT, { 'gen_ai.prompt': JSON.stringify(args[0]?.messages) });
            span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION, { 'gen_ai.completion': responses });
            const responseAttributes = {
                'url.full': url,
                'url.path': path,
                'gen_ai.usage.prompt_tokens': resp.usage.promptTokens,
                'gen_ai.usage.completion_tokens': resp.usage.completionTokens
            };
            span.setAttributes({ ...attributes, ...responseAttributes });
            span.setStatus({ code: api_1.SpanStatusCode.OK });
            return resp;
        }
        catch (error) {
            span.recordException(error);
            span.setStatus({ code: api_1.SpanStatusCode.ERROR });
            throw error;
        }
        finally {
            span.end();
        }
    });
}
exports.generateTextPatchOpenAI = generateTextPatchOpenAI;
async function embedPatchOpenAI(patchThis, args, originalMethod, method, tracer, langtraceVersion, sdkName, version) {
    let url;
    let path;
    // wrap the url method to get the url and path
    patchThis._wrap(args[0]?.model?.config, 'url', (originalMethod) => {
        return function (...args) {
            const result = originalMethod.apply(this, args);
            const uri = new URL(result);
            path = uri.pathname;
            url = uri.origin;
            return result;
        };
    });
    const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
    const attributes = {
        'langtrace.sdk.name': sdkName,
        'langtrace.service.name': trace_attributes_1.Vendors.VERCEL,
        'langtrace.service.type': 'framework',
        'langtrace.service.version': version,
        'langtrace.version': langtraceVersion,
        'gen_ai.request.model': args[0]?.model?.modelId,
        'url.full': '',
        'url.path': '',
        'gen_ai.request.dimensions': args[0]?.model?.settings?.dimensions,
        'gen_ai.request.embedding_inputs': args[0]?.value ?? JSON.stringify(args[0]?.values),
        'http.max.retries': args[0]?.maxRetries,
        'gen_ai.user': args[0]?.model?.settings?.user,
        ...customAttributes
    };
    const span = tracer.startSpan(method, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
    return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
        try {
            const resp = await originalMethod.apply(this, args);
            const responseAttributes = {
                'url.full': url,
                'url.path': path,
                'gen_ai.usage.total_tokens': Number.isNaN(resp?.usage?.tokens) ? undefined : resp?.usage?.tokens,
                'gen_ai.usage.prompt_tokens': resp.usage.promptTokens,
                'gen_ai.usage.completion_tokens': resp.usage.completionTokens
            };
            span.setAttributes({ ...attributes, ...responseAttributes });
            span.setStatus({ code: api_1.SpanStatusCode.OK });
            return resp;
        }
        catch (error) {
            span.recordException(error);
            span.setStatus({ code: api_1.SpanStatusCode.ERROR });
            throw error;
        }
        finally {
            span.end();
        }
    });
}
exports.embedPatchOpenAI = embedPatchOpenAI;
async function* handleOpenAIStreamResponse(span, stream, inputAttributes, promptTokens) {
    const result = [];
    let completionTokens = 0;
    const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
    span.addEvent(trace_attributes_1.Event.STREAM_START);
    try {
        for await (const chunk of stream) {
            const content = chunk.textDelta ?? chunk;
            completionTokens += (0, llm_1.estimateTokens)(content);
            if (chunk?.type === 'finish') {
                inputAttributes['gen_ai.usage.completion_tokens'] = chunk?.usage?.completionTokens;
                inputAttributes['gen_ai.usage.prompt_tokens'] = chunk?.usage?.promptTokens;
                inputAttributes['gen_ai.usage.total_tokens'] = chunk?.usage?.totalTokens;
            }
            else {
                inputAttributes['gen_ai.usage.completion_tokens'] = completionTokens;
                inputAttributes['gen_ai.usage.prompt_tokens'] = promptTokens;
                inputAttributes['gen_ai.usage.total_tokens'] = promptTokens + completionTokens;
            }
            if (content !== undefined && content.length > 0) {
                result.push(content);
                span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION_CHUNK, { 'gen_ai.completion.chunk': JSON.stringify({ role: 'assistant', content }) });
            }
            yield chunk;
        }
        span.addEvent(trace_attributes_1.Event.STREAM_END);
        span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION, { 'gen_ai.completion': result.length > 0 ? JSON.stringify([{ role: 'assistant', content: result.join('') }]) : undefined });
        span.setStatus({ code: api_1.SpanStatusCode.OK });
        span.setAttributes({ ...inputAttributes, ...customAttributes });
    }
    catch (error) {
        span.recordException(error);
        span.setStatus({ code: api_1.SpanStatusCode.ERROR });
        throw error;
    }
    finally {
        span.end();
    }
}
//# sourceMappingURL=openai.js.map