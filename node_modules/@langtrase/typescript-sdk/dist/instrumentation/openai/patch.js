"use strict";
/*
 * Copyright (c) 2024 Scale3 Labs
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.embeddingsCreate = exports.chatCompletionCreate = exports.imagesGenerate = exports.imageEdit = void 0;
const common_1 = require("../../constants/common");
const llm_1 = require("../../utils/llm");
const misc_1 = require("../../utils/misc");
const trace_attributes_1 = require("@langtrase/trace-attributes");
const api_1 = require("@opentelemetry/api");
function imageEdit(originalMethod, tracer, langtraceVersion, version) {
    return async function (...args) {
        // eslint-disable-next-line @typescript-eslint/no-this-alias
        const originalContext = this;
        const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
        // Determine the service provider
        let serviceProvider = trace_attributes_1.Vendors.OPENAI;
        if (originalContext?._client?.baseURL?.includes('azure') === true) {
            serviceProvider = 'azure';
        }
        const attributes = {
            'langtrace.sdk.name': '@langtrase/typescript-sdk',
            'langtrace.service.name': serviceProvider,
            'langtrace.service.type': 'llm',
            'langtrace.service.version': version,
            'langtrace.version': langtraceVersion,
            'url.full': originalContext?._client?.baseURL,
            'url.path': trace_attributes_1.APIS.openai.IMAGES_EDIT.ENDPOINT,
            'gen_ai.request.model': args[0]?.model ?? 'dall-e-2',
            'http.max.retries': originalContext?._client?.maxRetries,
            'http.timeout': originalContext?._client?.timeout,
            'gen_ai.request.top_k': args[0]?.n,
            'gen_ai.image.size': args[0]?.size,
            'gen_ai.response_format': args[0]?.response_format?.type ?? args[0]?.response_format,
            ...customAttributes
        };
        const span = tracer.startSpan(trace_attributes_1.APIS.openai.IMAGES_EDIT.METHOD, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
        const f = await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
            try {
                const response = await originalMethod.apply(originalContext, args);
                span.addEvent(trace_attributes_1.Event.GEN_AI_PROMPT, { 'gen_ai.prompt': JSON.stringify(args[0]?.prompt) });
                span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION, { 'gen_ai.completion': JSON.stringify(response?.data?.map((data) => ({ content: JSON.stringify(data), role: 'assistant' }))) });
                span.setAttributes(attributes);
                span.setStatus({ code: api_1.SpanStatusCode.OK });
                span.end();
                return response;
            }
            catch (error) {
                span.recordException(error);
                span.setStatus({ code: api_1.SpanStatusCode.ERROR });
                span.end();
                throw error;
            }
        });
        return f;
    };
}
exports.imageEdit = imageEdit;
function imagesGenerate(originalMethod, tracer, langtraceVersion, version) {
    return async function (...args) {
        // eslint-disable-next-line @typescript-eslint/no-this-alias
        const originalContext = this;
        // Determine the service provider
        let serviceProvider = trace_attributes_1.Vendors.OPENAI;
        if (originalContext?._client?.baseURL?.includes('azure') === true) {
            serviceProvider = 'azure';
        }
        const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
        const attributes = {
            'langtrace.sdk.name': '@langtrase/typescript-sdk',
            'langtrace.service.name': serviceProvider,
            'langtrace.service.type': 'llm',
            'langtrace.service.version': version,
            'langtrace.version': langtraceVersion,
            'url.full': originalContext?._client?.baseURL,
            'url.path': trace_attributes_1.APIS.openai.IMAGES_GENERATION.ENDPOINT,
            'gen_ai.request.model': args[0]?.model,
            'http.max.retries': originalContext?._client?.maxRetries,
            'http.timeout': originalContext?._client?.timeout,
            ...customAttributes
        };
        const span = tracer.startSpan(trace_attributes_1.APIS.openai.IMAGES_GENERATION.METHOD, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
        const f = await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
            try {
                const response = await originalMethod.apply(originalContext, args);
                span.addEvent(trace_attributes_1.Event.GEN_AI_PROMPT, { 'gen_ai.prompt': JSON.stringify([{ role: 'user', content: args[0]?.prompt }]) });
                span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION, { 'gen_ai.completion': JSON.stringify(response?.data?.map((data) => (({ content: JSON.stringify(data), role: 'assistant' })))) });
                span.setStatus({ code: api_1.SpanStatusCode.OK });
                span.end();
                return response;
            }
            catch (error) {
                span.recordException(error);
                span.setStatus({ code: api_1.SpanStatusCode.ERROR });
                span.end();
                throw error;
            }
        });
        return f;
    };
}
exports.imagesGenerate = imagesGenerate;
function chatCompletionCreate(originalMethod, tracer, langtraceVersion, version) {
    return async function (...args) {
        // eslint-disable-next-line @typescript-eslint/no-this-alias
        const originalContext = this;
        const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
        // Determine the service provider
        let serviceProvider = trace_attributes_1.Vendors.OPENAI;
        if (originalContext?._client?.baseURL?.includes('azure') === true) {
            serviceProvider = 'azure';
        }
        else if (originalContext?._client?.baseURL?.includes('perplexity') === true) {
            serviceProvider = 'perplexity';
        }
        const attributes = {
            'langtrace.sdk.name': '@langtrase/typescript-sdk',
            'langtrace.service.name': serviceProvider,
            'langtrace.service.type': 'llm',
            'langtrace.service.version': version,
            'langtrace.version': langtraceVersion,
            'gen_ai.request.model': args[0]?.model,
            'url.full': originalContext?._client?.baseURL,
            'url.path': trace_attributes_1.APIS.openai.CHAT_COMPLETION.ENDPOINT,
            'http.max.retries': originalContext?._client?.maxRetries,
            'http.timeout': originalContext?._client?.timeout,
            'gen_ai.request.stream': args[0]?.stream,
            'gen_ai.request.temperature': args[0]?.temperature,
            'gen_ai.request.top_p': args[0]?.top_p,
            'gen_ai.user': args[0]?.user,
            'gen_ai.request.max_tokens': args[0]?.max_tokens,
            'gen_ai.request.tools': JSON.stringify(args[0]?.tools),
            ...customAttributes
        };
        if (args[0]?.functions !== undefined) {
            const functionsToTools = args[0].functions.map((func) => {
                return {
                    function: func,
                    type: 'function'
                };
            });
            attributes['gen_ai.request.tools'] = JSON.stringify(functionsToTools);
        }
        if (!args[0].stream || args[0].stream === false) {
            const span = tracer.startSpan(trace_attributes_1.APIS.openai.CHAT_COMPLETION.METHOD, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
            return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
                try {
                    const resp = await originalMethod.apply(this, args);
                    const responses = resp?.choices?.map((choice) => {
                        const result = {
                            role: choice?.message?.role,
                            content: choice?.message?.content !== undefined && choice?.message?.content !== null
                                ? choice?.message?.content
                                : choice?.message?.function_call !== undefined
                                    ? JSON.stringify(choice?.message?.function_call)
                                    : JSON.stringify(choice?.message?.tool_calls)
                        };
                        return result;
                    });
                    span.addEvent(trace_attributes_1.Event.GEN_AI_PROMPT, { 'gen_ai.prompt': JSON.stringify(args[0]?.messages) });
                    span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION, { 'gen_ai.completion': JSON.stringify(responses) });
                    const responseAttributes = {
                        'gen_ai.response.model': resp.model,
                        'gen_ai.system_fingerprint': resp.system_fingerprint,
                        'gen_ai.usage.prompt_tokens': resp.usage.prompt_tokens,
                        'gen_ai.usage.completion_tokens': resp.usage.completion_tokens,
                        'gen_ai.usage.total_tokens': Number(resp.usage.prompt_tokens ?? 0) + Number(resp.usage.completion_tokens ?? 0)
                    };
                    span.setAttributes({ ...attributes, ...responseAttributes });
                    span.setStatus({ code: api_1.SpanStatusCode.OK });
                    return resp;
                }
                catch (error) {
                    span.recordException(error);
                    span.setStatus({ code: api_1.SpanStatusCode.ERROR });
                    throw error;
                }
                finally {
                    span.end();
                }
            });
        }
        else {
            const span = tracer.startSpan(trace_attributes_1.APIS.openai.CHAT_COMPLETION.METHOD, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
            span.addEvent(trace_attributes_1.Event.GEN_AI_PROMPT, { 'gen_ai.prompt': JSON.stringify(args[0]?.messages) });
            return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
                const model = args[0].model;
                // iterate over messages and calculate tokens
                const promptContent = args[0].messages.map((message) => message?.content).join(' ');
                const promptTokens = (0, llm_1.calculatePromptTokens)(promptContent, model);
                const resp = await originalMethod.apply(this, args);
                return (0, misc_1.createStreamProxy)(resp, handleStreamResponse(span, resp, promptTokens, attributes));
            });
        }
    };
}
exports.chatCompletionCreate = chatCompletionCreate;
async function* handleStreamResponse(span, stream, promptTokens, inputAttributes) {
    let completionTokens = 0;
    const result = [];
    const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
    span.addEvent(trace_attributes_1.Event.STREAM_START);
    try {
        let model = '';
        for await (const chunk of stream) {
            if (model === '') {
                model = chunk.model;
            }
            // eslint-disable-next-line @typescript-eslint/strict-boolean-expressions
            const content = chunk.choices[0]?.delta?.content || '';
            const tokenCount = (0, llm_1.estimateTokens)(content);
            completionTokens += tokenCount;
            result.push(content);
            if (chunk.choices[0]?.delta?.content !== undefined) {
                span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION_CHUNK, { 'gen_ai.completion.chunk': JSON.stringify({ role: chunk.choices[0]?.delta?.role ?? 'assistant', content: chunk.choices[0]?.delta?.content }) });
            }
            yield chunk;
        }
        span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION, { 'gen_ai.completion': result.length > 0 ? JSON.stringify([{ role: 'assistant', content: result.join('') }]) : undefined });
        span.setStatus({ code: api_1.SpanStatusCode.OK });
        const attributes = {
            'gen_ai.response.model': model,
            'gen_ai.usage.prompt_tokens': promptTokens,
            'gen_ai.usage.completion_tokens': completionTokens,
            'gen_ai.usage.total_tokens': promptTokens + completionTokens,
            ...customAttributes
        };
        span.setAttributes({ ...inputAttributes, ...attributes });
        span.addEvent(trace_attributes_1.Event.STREAM_END);
    }
    catch (error) {
        span.recordException(error);
        span.setStatus({ code: api_1.SpanStatusCode.ERROR });
        throw error;
    }
    finally {
        span.end();
    }
}
function embeddingsCreate(originalMethod, tracer, langtraceVersion, version) {
    return async function (...args) {
        // eslint-disable-next-line @typescript-eslint/no-this-alias
        const originalContext = this;
        const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
        // Determine the service provider
        let serviceProvider = trace_attributes_1.Vendors.OPENAI;
        if (originalContext?._client?.baseURL?.includes('azure') === true) {
            serviceProvider = 'azure';
        }
        const attributes = {
            'langtrace.sdk.name': '@langtrase/typescript-sdk',
            'langtrace.service.name': serviceProvider,
            'langtrace.service.type': 'llm',
            'langtrace.service.version': version,
            'langtrace.version': langtraceVersion,
            'url.full': originalContext?._client?.baseURL,
            'url.path': trace_attributes_1.APIS.openai.EMBEDDINGS_CREATE.ENDPOINT,
            'gen_ai.request.model': args[0]?.model,
            'http.max.retries': originalContext?._client?.maxRetries,
            'http.timeout': originalContext?._client?.timeout,
            'gen_ai.request.embedding_inputs': JSON.stringify([args[0]?.input]),
            'gen_ai.request.encoding_formats': args[0]?.encoding_format === undefined ? undefined : [args[0]?.encoding_format],
            'gen_ai.request.dimensions': args[0]?.dimensions,
            'gen_ai.user': args[0]?.user,
            ...customAttributes
        };
        const span = tracer.startSpan(trace_attributes_1.APIS.openai.EMBEDDINGS_CREATE.METHOD, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
        const f = await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
            try {
                const resp = await originalMethod.apply(originalContext, args);
                span.setStatus({ code: api_1.SpanStatusCode.OK });
                span.end();
                return resp;
            }
            catch (error) {
                span.recordException(error);
                span.setStatus({ code: api_1.SpanStatusCode.ERROR });
                span.end();
                throw error;
            }
        });
        return f;
    };
}
exports.embeddingsCreate = embeddingsCreate;
//# sourceMappingURL=patch.js.map