"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.chatStreamPatch = exports.chatPatchNonStreamed = exports.chatPatch = void 0;
const api_1 = require("@opentelemetry/api");
const common_1 = require("../../constants/common");
const trace_attributes_1 = require("@langtrase/trace-attributes");
const misc_1 = require("../../utils/misc");
const chatPatch = (original, tracer, langtraceVersion, sdkName, moduleVersion) => {
    return async function (body, options) {
        if (body.stream === true) {
            return await (0, exports.chatStreamPatch)(original, tracer, langtraceVersion, sdkName, moduleVersion).apply(this, [body, options]);
        }
        return await (0, exports.chatPatchNonStreamed)(original, tracer, langtraceVersion, sdkName, moduleVersion).apply(this, [body, options]);
    };
};
exports.chatPatch = chatPatch;
const chatPatchNonStreamed = (original, tracer, langtraceVersion, sdkName, moduleVersion) => {
    return async function (body, options) {
        const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
        const attributes = {
            'langtrace.sdk.name': sdkName,
            'langtrace.service.name': 'groq',
            'langtrace.service.type': 'llm',
            'langtrace.service.version': moduleVersion,
            'langtrace.version': langtraceVersion,
            'url.full': this?._client?.baseURL,
            'url.path': trace_attributes_1.APIS.groq.CHAT_COMPLETION.ENDPOINT,
            'gen_ai.request.model': body.model,
            'http.max.retries': options?.maxRetries ?? this._client.maxRetries,
            'http.timeout': options?.timeout ?? this._client.timeout,
            'gen_ai.request.stream': body?.stream ?? false,
            'gen_ai.request.temperature': body.temperature,
            'gen_ai.request.top_p': body.top_p,
            'gen_ai.request.top_logprobs': body.top_logprobs,
            'gen_ai.request.top_k': body.n,
            'gen_ai.user': body.user,
            'gen_ai.request.frequency_penalty': body?.frequency_penalty,
            'gen_ai.request.presence_penalty': body?.presence_penalty,
            'gen_ai.request.max_tokens': body?.max_tokens,
            'gen_ai.request.tools': JSON.stringify(body.tools),
            ...customAttributes
        };
        const span = tracer.startSpan(trace_attributes_1.APIS.groq.CHAT_COMPLETION.METHOD, { attributes, kind: api_1.SpanKind.CLIENT }, api_1.context.active());
        return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
            try {
                const resp = await original.apply(this, [body, options]);
                const responses = resp?.choices?.map(({ message }) => {
                    const result = {
                        role: message?.role,
                        content: message?.content !== undefined && message?.content !== null
                            ? message?.content
                            : JSON.stringify(message?.tool_calls)
                    };
                    return result;
                });
                span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION, { 'gen_ai.completion': JSON.stringify(responses) });
                attributes['gen_ai.system_fingerprint'] = resp?.system_fingerprint;
                attributes['gen_ai.response.model'] = resp.model;
                attributes['gen_ai.usage.prompt_tokens'] = resp?.usage?.prompt_tokens;
                attributes['gen_ai.usage.completion_tokens'] = resp?.usage?.completion_tokens;
                attributes['gen_ai.usage.total_tokens'] = resp?.usage?.total_tokens;
                span.setAttributes(attributes);
                span.setStatus({ code: api_1.SpanStatusCode.OK });
                return resp;
            }
            finally {
                span.end();
            }
        });
    };
};
exports.chatPatchNonStreamed = chatPatchNonStreamed;
const chatStreamPatch = (original, tracer, langtraceVersion, sdkName, moduleVersion) => {
    return async function (body, options) {
        const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
        const attributes = {
            'langtrace.sdk.name': sdkName,
            'langtrace.service.name': 'groq',
            'langtrace.service.type': 'llm',
            'langtrace.service.version': moduleVersion,
            'langtrace.version': langtraceVersion,
            'url.full': this?._client?.baseURL,
            'url.path': trace_attributes_1.APIS.groq.CHAT_COMPLETION.ENDPOINT,
            'gen_ai.request.model': body.model,
            'http.max.retries': options?.maxRetries ?? this._client.maxRetries,
            'http.timeout': options?.timeout ?? this._client.timeout,
            'gen_ai.request.stream': body?.stream ?? true,
            'gen_ai.request.temperature': body.temperature,
            'gen_ai.request.top_p': body.top_p,
            'gen_ai.request.top_logprobs': body.top_logprobs,
            'gen_ai.request.top_k': body.n,
            'gen_ai.user': body.user,
            'gen_ai.request.frequency_penalty': body?.frequency_penalty,
            'gen_ai.request.presence_penalty': body?.presence_penalty,
            'gen_ai.request.max_tokens': body?.max_tokens,
            'gen_ai.request.tools': JSON.stringify(body.tools),
            ...customAttributes
        };
        const span = tracer.startSpan(trace_attributes_1.APIS.groq.CHAT_COMPLETION.METHOD, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
        return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
            const resp = await original.apply(this, [body, options]);
            return (0, misc_1.createStreamProxy)(resp, handleStream(resp, attributes, span));
        });
    };
};
exports.chatStreamPatch = chatStreamPatch;
async function* handleStream(stream, attributes, span) {
    const responseReconstructed = [];
    try {
        span.addEvent(trace_attributes_1.Event.STREAM_START);
        let role;
        for await (const chunk of stream) {
            const content = chunk.choices[0].delta.content;
            const r = chunk.choices[0].delta.role;
            if (r !== undefined) {
                role = r;
            }
            if (content !== undefined) {
                span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION_CHUNK, { 'gen_ai.completion.chunk': JSON.stringify({ role, content }) });
            }
            responseReconstructed.push(chunk.choices[0].delta.content ?? '');
            if (chunk.choices[0].finish_reason === 'stop') {
                attributes['gen_ai.usage.completion_tokens'] = chunk.x_groq?.usage?.completion_tokens;
                attributes['gen_ai.usage.prompt_tokens'] = chunk.x_groq?.usage?.prompt_tokens;
                attributes['gen_ai.usage.total_tokens'] = Number(chunk.x_groq?.usage?.completion_tokens ?? 0) + Number(chunk.x_groq?.usage?.prompt_tokens ?? 0);
                attributes['gen_ai.response.model'] = chunk?.model;
                attributes['gen_ai.system_fingerprint'] = chunk?.system_fingerprint;
            }
            yield chunk;
        }
        span.addEvent(trace_attributes_1.Event.STREAM_END);
        span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION, { 'gen_ai.completion': JSON.stringify([{ role: 'assistant', content: responseReconstructed.join('') }]) });
        span.setAttributes(attributes);
        span.setStatus({ code: api_1.SpanStatusCode.OK });
    }
    catch (error) {
        span.recordException(error);
        span.setStatus({ code: api_1.SpanStatusCode.ERROR });
        throw error;
    }
    finally {
        span.end();
    }
}
//# sourceMappingURL=patch.js.map