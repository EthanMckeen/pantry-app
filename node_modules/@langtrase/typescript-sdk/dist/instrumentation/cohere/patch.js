"use strict";
/* eslint-disable @typescript-eslint/no-unsafe-return */
/*
 * Copyright (c) 2024 Scale3 Labs
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.rerankPatch = exports.embedJobsCreatePatch = exports.embedPatch = exports.chatStreamPatch = exports.chatPatch = void 0;
const common_1 = require("../../constants/common");
const api_1 = require("@opentelemetry/api");
const trace_attributes_1 = require("@langtrase/trace-attributes");
const misc_1 = require("../../utils/misc");
const chatPatch = (original, tracer, langtraceVersion, sdkName, moduleVersion) => {
    return async function (request, requestOptions) {
        const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
        const attributes = {
            'langtrace.sdk.name': sdkName,
            'langtrace.service.name': this._options.clientName ?? 'cohere',
            'langtrace.service.type': 'llm',
            'langtrace.version': langtraceVersion,
            'langtrace.service.version': moduleVersion,
            'url.full': 'https://api.cohere.ai',
            'url.path': trace_attributes_1.APIS.cohere.CHAT.ENDPOINT,
            'gen_ai.request.model': request.model ?? 'command-r',
            'http.max.retries': requestOptions?.maxRetries,
            'gen_ai.request.temperature': request.temperature,
            'gen_ai.request.frequency_penalty': request.frequencyPenalty,
            'gen_ai.request.presence_penalty': request.presencePenalty,
            'gen_ai.request.top_p': request.p,
            'gen_ai.request.top_k': request.k,
            'gen_ai.request.seed': request.seed?.toString(),
            'gen_ai.request.max_tokens': request.maxTokens,
            'gen_ai.request.documents': request.documents !== undefined ? JSON.stringify(request.documents) : undefined,
            'gen_ai.request.tools': request.tools !== undefined ? JSON.stringify(request.tools) : undefined,
            'gen_ai.request.tool_results': request.tools !== undefined ? JSON.stringify(request.toolResults) : undefined,
            'gen_ai.request.connectors': request.connectors !== undefined ? JSON.stringify(request.connectors) : undefined,
            'http.timeout': requestOptions?.timeoutInSeconds !== undefined ? requestOptions.timeoutInSeconds / 1000 : undefined,
            ...customAttributes
        };
        const span = tracer.startSpan(trace_attributes_1.APIS.cohere.CHAT.METHOD, { attributes, kind: api_1.SpanKind.CLIENT }, api_1.context.active());
        try {
            return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
                const prompts = [];
                if (request.preamble !== undefined && request.preamble !== '') {
                    prompts.push({ role: 'system', content: request.preamble });
                }
                if (request.chatHistory !== undefined) {
                    prompts.push(...request.chatHistory.map((chat) => { return { role: chat.role === 'CHATBOT' ? 'assistant' : chat.role.toLowerCase(), content: chat.message }; }));
                }
                prompts.push({ role: 'user', content: request.message });
                const response = await original.apply(this, [request, requestOptions]);
                const responseAttributes = {
                    'gen_ai.usage.prompt_tokens': response.meta?.billedUnits?.inputTokens,
                    'gen_ai.usage.completion_tokens': response.meta?.billedUnits?.outputTokens,
                    'gen_ai.usage.total_tokens': Number(response.meta?.billedUnits?.inputTokens ?? 0) + Number(response.meta?.billedUnits?.outputTokens ?? 0),
                    'gen_ai.usage.search_units': response.meta?.billedUnits?.searchUnits,
                    'gen_ai.response_id': response.response_id,
                    'gen_ai.response.tool_calls': response.toolCalls !== undefined ? JSON.stringify(response.toolCalls) : undefined
                };
                span.addEvent(trace_attributes_1.Event.GEN_AI_PROMPT, { 'gen_ai.prompt': JSON.stringify(prompts) });
                if (response.chatHistory !== undefined) {
                    span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION, { 'gen_ai.completion': JSON.stringify(response.chatHistory.map((chat) => { return { role: chat.role === 'CHATBOT' ? 'assistant' : chat.role.toLowerCase(), content: chat.message }; })) });
                }
                else {
                    span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION, { 'gen_ai.completion': JSON.stringify([{ role: 'assistant', content: response.text }]) });
                }
                span.setAttributes({ ...attributes, ...responseAttributes });
                span.setStatus({ code: api_1.SpanStatusCode.OK });
                return response;
            });
        }
        catch (e) {
            span.recordException(e);
            span.setStatus({ code: api_1.SpanStatusCode.ERROR });
            throw e;
        }
        finally {
            span.end();
        }
    };
};
exports.chatPatch = chatPatch;
const chatStreamPatch = (original, tracer, langtraceVersion, sdkName, moduleVersion) => {
    return async function (request, requestOptions) {
        const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
        const attributes = {
            'langtrace.sdk.name': sdkName,
            'langtrace.service.name': this._options.clientName ?? 'cohere',
            'langtrace.service.type': 'llm',
            'langtrace.version': langtraceVersion,
            'langtrace.service.version': moduleVersion,
            'url.full': 'https://api.cohere.ai',
            'url.path': trace_attributes_1.APIS.cohere.CHAT.ENDPOINT,
            'gen_ai.request.stream': true,
            'gen_ai.request.model': request.model ?? 'command-r',
            'http.max.retries': requestOptions?.maxRetries,
            'gen_ai.request.temperature': request.temperature,
            'gen_ai.request.frequency_penalty': request.frequencyPenalty,
            'gen_ai.request.presence_penalty': request.presencePenalty,
            'gen_ai.request.top_p': request.p,
            'gen_ai.request.top_k': request.k,
            'gen_ai.request.max_tokens': request.maxTokens,
            'gen_ai.request.seed': request.seed?.toString(),
            'gen_ai.request.documents': request.documents !== undefined ? JSON.stringify(request.documents) : undefined,
            'gen_ai.request.tools': request.tools !== undefined ? JSON.stringify(request.tools) : undefined,
            'gen_ai.request.tool_results': request.tools !== undefined ? JSON.stringify(request.toolResults) : undefined,
            'gen_ai.request.connectors': request.connectors !== undefined ? JSON.stringify(request.connectors) : undefined,
            'http.timeout': requestOptions?.timeoutInSeconds !== undefined ? requestOptions.timeoutInSeconds / 1000 : undefined,
            ...customAttributes
        };
        const span = tracer.startSpan(trace_attributes_1.APIS.cohere.CHAT_STREAM.METHOD, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
        return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
            const prompts = [];
            if (request.preamble !== undefined && request.preamble !== '') {
                prompts.push({ role: 'system', content: request.preamble });
            }
            if (request.chatHistory !== undefined) {
                prompts.push(...request.chatHistory.map((chat) => { return { role: chat.role === 'CHATBOT' ? 'assistant' : chat.role.toLowerCase(), content: chat.message }; }));
            }
            prompts.push({ role: 'user', content: request.message });
            span.addEvent(trace_attributes_1.Event.GEN_AI_PROMPT, { 'gen_ai.prompt': JSON.stringify(prompts) });
            const response = await original.apply(this, [request, requestOptions]);
            return (0, misc_1.createStreamProxy)(response, handleStream(response, attributes, span));
        });
    };
};
exports.chatStreamPatch = chatStreamPatch;
const embedPatch = (original, tracer, langtraceVersion, sdkName, moduleVersion) => {
    return async function (request, requestOptions) {
        const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
        const attributes = {
            'langtrace.sdk.name': sdkName,
            'langtrace.service.name': this._options.clientName ?? 'cohere',
            'langtrace.service.type': 'llm',
            'langtrace.version': langtraceVersion,
            'langtrace.service.version': moduleVersion,
            'url.full': 'https://api.cohere.ai',
            'url.path': trace_attributes_1.APIS.cohere.EMBED.ENDPOINT,
            'gen_ai.request.model': request.model ?? 'embed-english-v2.0',
            'http.max.retries': requestOptions?.maxRetries,
            'gen_ai.request.embedding_input_type': request.inputType,
            'gen_ai.request.encoding_formats': request.embeddingTypes,
            'gen_ai.request.embedding_inputs': JSON.stringify(request.texts),
            'http.timeout': requestOptions?.timeoutInSeconds !== undefined ? requestOptions.timeoutInSeconds / 1000 : undefined,
            ...customAttributes
        };
        const span = tracer.startSpan(trace_attributes_1.APIS.cohere.EMBED.METHOD, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
        try {
            return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
                const response = await original.apply(this, [request, requestOptions]);
                attributes['gen_ai.usage.completion_tokens'] = response.meta?.billedUnits?.outputTokens;
                attributes['gen_ai.usage.prompt_tokens'] = response.meta?.billedUnits?.inputTokens;
                attributes['gen_ai.usage.total_tokens'] = Number(response.meta?.billedUnits?.inputTokens ?? 0) + Number(response.meta?.billedUnits?.outputTokens ?? 0);
                attributes['gen_ai.usage.search_units'] = response.meta?.billedUnits?.searchUnits;
                span.setAttributes(attributes);
                span.setStatus({ code: api_1.SpanStatusCode.OK });
                return response;
            });
        }
        catch (e) {
            span.recordException(e);
            span.setStatus({ code: api_1.SpanStatusCode.ERROR });
            throw e;
        }
        finally {
            span.end();
        }
    };
};
exports.embedPatch = embedPatch;
const embedJobsCreatePatch = (original, tracer, langtraceVersion, sdkName, moduleVersion) => {
    return async function (request, requestOptions) {
        const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
        const attributes = {
            'langtrace.sdk.name': sdkName,
            'langtrace.service.name': this._options.clientName ?? 'cohere',
            'langtrace.service.type': 'llm',
            'langtrace.version': langtraceVersion,
            'langtrace.service.version': moduleVersion,
            'url.full': 'https://api.cohere.ai',
            'url.path': trace_attributes_1.APIS.cohere.EMBED_JOBS.ENDPOINT,
            'gen_ai.request.model': request.model,
            'http.max.retries': requestOptions?.maxRetries,
            'gen_ai.request.embedding_input_type': request.inputType,
            'gen_ai.request.encoding_formats': request.embeddingTypes,
            'gen_ai.request.embedding_job_name': request.name,
            'gen_ai.request.embedding_dataset_id': request.datasetId,
            'http.timeout': requestOptions?.timeoutInSeconds !== undefined ? requestOptions.timeoutInSeconds / 1000 : undefined,
            ...customAttributes
        };
        const span = tracer.startSpan(trace_attributes_1.APIS.cohere.EMBED_JOBS.METHOD, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
        try {
            return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
                const response = await original.apply(this, [request, requestOptions]);
                attributes['gen_ai.usage.completion_tokens'] = response.meta?.billedUnits?.outputTokens;
                attributes['gen_ai.usage.prompt_tokens'] = response.meta?.billedUnits?.inputTokens;
                attributes['gen_ai.usage.total_tokens'] = Number(response.meta?.billedUnits?.inputTokens ?? 0) + Number(response.meta?.billedUnits?.outputTokens ?? 0);
                attributes['gen_ai.usage.search_units'] = response.meta?.billedUnits?.searchUnits;
                span.setAttributes(attributes);
                span.setStatus({ code: api_1.SpanStatusCode.OK });
                return response;
            });
        }
        catch (e) {
            span.setStatus({ code: api_1.SpanStatusCode.ERROR });
            span.recordException(e);
            throw e;
        }
        finally {
            span.end();
        }
    };
};
exports.embedJobsCreatePatch = embedJobsCreatePatch;
const rerankPatch = (original, tracer, langtraceVersion, sdkName, moduleVersion) => {
    return async function (request, requestOptions) {
        const customAttributes = api_1.context.active().getValue(common_1.LANGTRACE_ADDITIONAL_SPAN_ATTRIBUTES_KEY) ?? {};
        const attributes = {
            'langtrace.sdk.name': sdkName,
            'langtrace.service.name': this._options.clientName ?? 'cohere',
            'langtrace.service.type': 'llm',
            'gen_ai.cohere.rerank.query': request.query,
            'langtrace.version': langtraceVersion,
            'langtrace.service.version': moduleVersion,
            'url.full': 'https://api.cohere.ai',
            'url.path': trace_attributes_1.APIS.cohere.RERANK.ENDPOINT,
            'gen_ai.request.model': request.model,
            'http.max.retries': requestOptions?.maxRetries,
            'gen_ai.request.documents': JSON.stringify(request.documents),
            'gen_ai.request.top_k': request.topN,
            'http.timeout': requestOptions?.timeoutInSeconds !== undefined ? requestOptions.timeoutInSeconds / 1000 : undefined,
            ...customAttributes
        };
        const span = tracer.startSpan(trace_attributes_1.APIS.cohere.RERANK.METHOD, { kind: api_1.SpanKind.CLIENT, attributes }, api_1.context.active());
        try {
            return await api_1.context.with(api_1.trace.setSpan(api_1.context.active(), span), async () => {
                const response = await original.apply(this, [request, requestOptions]);
                attributes['gen_ai.cohere.rerank.results'] = JSON.stringify(response.results);
                attributes['gen_ai.response_id'] = response.id;
                attributes['gen_ai.usage.completion_tokens'] = response.meta?.billedUnits?.outputTokens;
                attributes['gen_ai.usage.total_tokens'] = Number(response.meta?.billedUnits?.inputTokens ?? 0) + Number(response.meta?.billedUnits?.outputTokens ?? 0);
                attributes['gen_ai.usage.prompt_tokens'] = response.meta?.billedUnits?.inputTokens;
                attributes['gen_ai.usage.search_units'] = response.meta?.billedUnits?.searchUnits;
                span.setAttributes(attributes);
                span.setStatus({ code: api_1.SpanStatusCode.OK });
                return response;
            });
        }
        catch (e) {
            span.recordException(e);
            span.setStatus({ code: api_1.SpanStatusCode.ERROR });
            throw e;
        }
        finally {
            span.end();
        }
    };
};
exports.rerankPatch = rerankPatch;
async function* handleStream(stream, attributes, span) {
    try {
        span.addEvent(trace_attributes_1.Event.STREAM_START);
        for await (const chat of stream) {
            if (chat.eventType === 'text-generation') {
                span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION_CHUNK, { 'gen_ai.completion.chunk': JSON.stringify({ role: 'assistant', content: chat.text }) });
            }
            if (chat.eventType === 'stream-end') {
                span.addEvent(trace_attributes_1.Event.STREAM_END);
                let response = [];
                if (chat.response.chatHistory !== undefined) {
                    response = chat.response.chatHistory.map((chat) => { return { role: chat.role === 'CHATBOT' ? 'assistant' : chat.role.toLowerCase(), content: chat.message }; });
                }
                else {
                    response = { role: chat.role === 'CHATBOT' ? 'assistant' : chat.role === 'SYSTEM' ? 'system' : 'user', content: chat.response.text };
                }
                span.addEvent(trace_attributes_1.Event.GEN_AI_COMPLETION, { 'gen_ai.completion': JSON.stringify(response) });
                attributes['gen_ai.usage.completion_tokens'] = chat.response.meta?.billedUnits?.outputTokens;
                attributes['gen_ai.usage.prompt_tokens'] = chat.response.meta?.billedUnits?.inputTokens;
                attributes['gen_ai.usage.total_tokens'] = Number(chat.response.meta?.billedUnits?.inputTokens ?? 0) + Number(chat.response.meta?.billedUnits?.outputTokens ?? 0);
                attributes['gen_ai.usage.search_units'] = chat.response.meta?.billedUnits?.searchUnits;
                attributes['gen_ai.response.tool_calls'] = chat.response.toolCalls !== undefined ? JSON.stringify(chat.response.toolCalls) : undefined;
                attributes['gen_ai.response_id'] = chat.response.response_id;
            }
            yield chat;
        }
        span.setAttributes(attributes);
        span.setStatus({ code: api_1.SpanStatusCode.OK });
    }
    catch (error) {
        span.recordException(error);
        span.setStatus({ code: api_1.SpanStatusCode.ERROR });
        throw error;
    }
    finally {
        span.end();
    }
}
//# sourceMappingURL=patch.js.map